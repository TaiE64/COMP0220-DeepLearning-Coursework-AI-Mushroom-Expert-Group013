#!/usr/bin/env python3
"""
ğŸ“‹ åŸºäºè§„åˆ™çš„é€šç”¨è¯é¢˜ Q&A ç”Ÿæˆå™¨
ä¸“é—¨å¤„ç†æ¦‚å¿µæ€§è¯é¢˜ï¼ˆçœŸèŒã€èŒä¸ã€æ ½åŸ¹ã€çƒ¹é¥ªç­‰ï¼‰
"""

import json
import random
import re

# ================= é…ç½® =================
INPUT_FILE = "data/raw_data_source/raw_mushroom_wiki_data.json"
OUTPUT_FILE = "data/processed/mushroom_rule_based_short.jsonl"
# =======================================

# é€šç”¨è¯é¢˜æ¨¡æ¿ï¼ˆé€‚åˆæ¦‚å¿µã€è¿‡ç¨‹ã€æ–¹æ³•ï¼‰
TEMPLATES = {
    "summary": [
        "What is {topic}?",
        "Tell me about {topic}.",
        "Can you explain {topic}?",
        "What does {topic} mean?",
        "Could you describe {topic}?"
    ],

    # ç‰¹å¾/æ€§è´¨ç±»
    "characteristics": [
        "What are the characteristics of {topic}?",
        "What are the key features of {topic}?",
        "How does {topic} work?",
        "What makes {topic} unique?"
    ],

    # è¿‡ç¨‹/æ–¹æ³•ç±»
    "process": [
        "How does {topic} occur?",
        "What is the process of {topic}?",
        "How is {topic} done?",
        "What steps are involved in {topic}?"
    ],

    # åŠŸèƒ½/ç”¨é€”ç±»
    "function": [
        "What is {topic} used for?",
        "Why is {topic} important?",
        "What role does {topic} play?",
        "How is {topic} applied?"
    ],

    # è¯†åˆ«/æ£€æµ‹ç±»
    "identification": [
        "How can you identify {topic}?",
        "What are the signs of {topic}?",
        "How do you recognize {topic}?",
        "What indicates {topic}?"
    ],

    # ç±»å‹/åˆ†ç±»ç±»
    "types": [
        "What are the types of {topic}?",
        "What are different kinds of {topic}?",
        "How is {topic} classified?",
        "What variations of {topic} exist?"
    ],

    # å®‰å…¨/é£é™©ç±»
    "safety": [
        "Is {topic} dangerous?",
        "What are the risks of {topic}?",
        "How to stay safe with {topic}?",
        "What precautions should be taken with {topic}?"
    ]
}

# ç« èŠ‚åç§°åˆ°æ¨¡æ¿ç±»å‹çš„æ˜ å°„
SECTION_TO_TEMPLATE = {
    # ç”Ÿç‰©å­¦/å½¢æ€å­¦
    "characteristics": ["characteristics", "summary"],
    "morphology": ["characteristics", "summary"],
    "structure": ["characteristics", "summary"],
    "anatomy": ["characteristics", "summary"],
    "biology": ["characteristics", "summary"],

    # è¿‡ç¨‹/ç”Ÿå‘½å‘¨æœŸ
    "life cycle": ["process", "summary"],
    "reproduction": ["process", "summary"],
    "development": ["process", "summary"],
    "growth": ["process", "summary"],

    # åˆ†ç±»/ç±»å‹
    "classification": ["types", "summary"],
    "types": ["types", "summary"],
    "taxonomy": ["types", "summary"],
    "species": ["types", "summary"],

    # ç”Ÿæ€/åˆ†å¸ƒ
    "ecology": ["characteristics", "function"],
    "habitat": ["characteristics", "summary"],
    "distribution": ["summary"],

    # è¯†åˆ«/æ£€æµ‹
    "identification": ["identification", "characteristics"],
    "diagnosis": ["identification", "characteristics"],
    "detection": ["identification", "characteristics"],
    "recognition": ["identification", "characteristics"],

    # æ¯’æ€§/å®‰å…¨
    "toxicity": ["safety", "summary"],
    "poisoning": ["safety", "summary"],
    "symptoms": ["safety", "identification"],
    "treatment": ["safety", "process"],

    # ç”¨é€”/åº”ç”¨
    "uses": ["function", "summary"],
    "applications": ["function", "summary"],
    "cultivation": ["process", "function"],
    "cooking": ["process", "function"],
    "preparation": ["process", "summary"],

    # å†å²/æ–‡åŒ–
    "history": ["summary"],
    "etymology": ["summary"],
    "culture": ["summary", "function"]
}

def clean_text(text):
    """æ¸…æ´—æ–‡æœ¬ï¼šå»å¼•ç”¨ã€å»å¤šä½™ç©ºæ ¼"""
    text = re.sub(r'\[\d+\]', '', text)
    text = text.replace('\n', ' ')
    return " ".join(text.split())

def smart_shorten(text, max_sentences=3):
    """
    æ™ºèƒ½ç¼©çŸ­æ–‡æœ¬åˆ°æŒ‡å®šå¥å­æ•°
    """
    if not text:
        return ""

    sentences = text.split('. ')
    final_sentences = []

    for s in sentences:
        clean_s = s.strip()
        if not clean_s or len(clean_s) < 20:  # è·³è¿‡å¤ªçŸ­çš„å¥å­
            continue

        if not clean_s.endswith('.'):
            clean_s += '.'

        final_sentences.append(clean_s)

        if len(final_sentences) >= max_sentences:
            break

    return " ".join(final_sentences)

def match_section_to_templates(section_name):
    """
    æ ¹æ®ç« èŠ‚åç§°åŒ¹é…åˆé€‚çš„é—®é¢˜æ¨¡æ¿
    """
    section_lower = section_name.lower()

    # å°è¯•ç²¾ç¡®åŒ¹é…
    for keyword, template_types in SECTION_TO_TEMPLATE.items():
        if keyword in section_lower:
            return template_types

    # é»˜è®¤è¿”å›é€šç”¨æ¨¡æ¿
    return ["summary", "characteristics"]

# ================= ä¸»é€»è¾‘ =================
print("=" * 80)
print("ğŸ“‹ åŸºäºè§„åˆ™ç”Ÿæˆé€šç”¨è¯é¢˜ Q&A")
print("=" * 80)

formatted_data = []

try:
    with open(INPUT_FILE, 'r', encoding='utf-8') as f:
        raw_data = json.load(f)
except FileNotFoundError:
    print(f"âŒ æ‰¾ä¸åˆ° {INPUT_FILE}")
    print(f"ğŸ’¡ è¯·å…ˆè¿è¡Œ: python data/scripts/scrape_related_topics.py")
    exit()

for item in raw_data:
    topic = item['topic']

    # --- 1. å¤„ç† Summary (å®šä¹‰) ---
    if item.get('summary'):
        question = random.choice(TEMPLATES["summary"]).format(topic=topic)
        answer = smart_shorten(clean_text(item['summary']), max_sentences=3)

        if answer:
            formatted_data.append({
                "text": f"User: {question}\nAssistant: {answer}<|im_end|>"
            })

    # --- 2. å¤„ç†å„ä¸ª Section ---
    sections = item.get('sections', {})

    for section_name, section_content in sections.items():
        # æ ¹æ®ç« èŠ‚åç§°é€‰æ‹©åˆé€‚çš„æ¨¡æ¿
        template_types = match_section_to_templates(section_name)

        # éšæœºé€‰æ‹©ä¸€ä¸ªæ¨¡æ¿ç±»å‹
        template_type = random.choice(template_types)

        # ç”Ÿæˆé—®é¢˜
        if template_type in TEMPLATES:
            question_template = random.choice(TEMPLATES[template_type])
            question = question_template.format(topic=topic)

            # ç”Ÿæˆç­”æ¡ˆ
            answer = smart_shorten(clean_text(section_content), max_sentences=3)

            if answer:
                formatted_data.append({
                    "text": f"User: {question}\nAssistant: {answer}<|im_end|>"
                })

# ================= ä¿å­˜æ•°æ® =================
print(f"\nâœ… æ€»è®¡ç”Ÿæˆ {len(formatted_data)} æ¡ Q&A")

with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
    for item in formatted_data:
        json.dump(item, f, ensure_ascii=False)
        f.write('\n')

print(f"ğŸ“ ä¿å­˜åˆ°: {OUTPUT_FILE}")

# é¢„è§ˆ
print("\nğŸ“ æ•°æ®é¢„è§ˆï¼ˆå‰5æ¡ï¼‰:")
for i, item in enumerate(formatted_data[:5], 1):
    print(f"\nã€{i}ã€‘")
    print(item['text'][:200] + "...")

print("\n" + "=" * 80)
print("ğŸ‰ å®Œæˆï¼")
