import json
import random
import re

# ================= é…ç½® =================
INPUT_FILE = "data/raw_data_source/related_topics_wiki_data.json"
OUTPUT_FILE = "data/processed/mushroom_rule_based_related_topics.jsonl"
# =======================================

TEMPLATES = {
    "summary": [
        "What is {topic}?",
        "Tell me about {topic}.",
        "Can you explain what {topic} is?"
    ],
    "Description": [
        "What does {topic} look like?",
        "Describe the appearance of {topic}.",
        "How can I identify {topic}?"
    ],
    "Toxicity": [
        "Is {topic} poisonous?",
        "Can I eat {topic}?",
        "Is {topic} safe?"
    ],
    "Habitat": [
        "Where does {topic} grow?",
        "What is the habitat of {topic}?",
        "Where can I find {topic}?"
    ],
    "Edibility": [
        "Is {topic} edible?",
        "Can you eat {topic}?",
        "Is {topic} good to eat?"
    ]
}

def clean_text(text):
    """åŸºç¡€æ¸…æ´—ï¼šå»å¼•ç”¨ã€å»å¤šä½™ç©ºæ ¼"""
    # å»é™¤ [1], [12] è¿™ç§å¼•ç”¨
    text = re.sub(r'\[\d+\]', '', text)
    # å»é™¤æ¢è¡Œ
    text = text.replace('\n', ' ')
    return " ".join(text.split())

def smart_shorten(text, max_sentences=2):
    """
    æ ¸å¿ƒå‡½æ•°ï¼šæŠŠé•¿æ®µè½å˜çŸ­ï¼Œå˜æˆé€‚åˆèŠå¤©çš„é•¿åº¦ã€‚
    ç­–ç•¥ï¼šåªå–å‰ N å¥ã€‚
    """
    if not text:
        return ""

    # 1. æŒ‰å¥å·+ç©ºæ ¼åˆ‡åˆ†
    sentences = text.split('. ')

    # 2. å¦‚æœç¬¬ä¸€å¥å¤ªçŸ­ï¼ˆæ¯”å¦‚åªæ˜¯ä¸ªåˆ†ç±»åï¼‰ï¼Œå¯èƒ½è¦å¤šå–ä¸€å¥
    final_sentences = []
    current_len = 0

    for s in sentences:
        clean_s = s.strip()
        if not clean_s:
            continue

        # è¡¥å›å¥å·
        if not clean_s.endswith('.'):
            clean_s += '.'

        final_sentences.append(clean_s)
        current_len += 1

        # è¾¾åˆ°æ•°é‡é™åˆ¶å°±åœæ­¢
        if current_len >= max_sentences:
            break

    return " ".join(final_sentences)

# ================= ä¸»é€»è¾‘ =================
print("=" * 60)
print("æ­£åœ¨ç”Ÿæˆç²¾ç®€ç‰ˆå¯¹è¯æ•°æ®...")
print("=" * 60)

formatted_data = []

try:
    with open(INPUT_FILE, 'r', encoding='utf-8') as f:
        raw_data = json.load(f)
except FileNotFoundError:
    print(f"âŒ æ‰¾ä¸åˆ° {INPUT_FILE}ï¼Œè¯·å…ˆè¿è¡Œçˆ¬è™«è„šæœ¬ï¼")
    exit()

for item in raw_data:
    topic = item['topic']

    # --- 1. å¤„ç† Summary (å®šä¹‰) ---
    # ç­–ç•¥ï¼šSummary é€šå¸¸åŒ…å«å®šä¹‰+åˆ†å¸ƒ+å†å²ã€‚æˆ‘ä»¬åªè¦å‰2å¥å®šä¹‰ã€‚
    if item.get('summary'):
        question = random.choice(TEMPLATES["summary"]).format(topic=topic)

        raw_answer = clean_text(item['summary'])
        short_answer = smart_shorten(raw_answer, max_sentences=2)  # åªå–å‰2å¥

        if short_answer:
            formatted_data.append({
                "text": f"User: {question}\nAssistant: {short_answer}<|im_end|>"
            })

    # --- 2. å¤„ç†å„ç§ç« èŠ‚ ---
    sections = item.get('sections', {})

    # éå†æ¨¡æ¿ï¼ŒæŸ¥æ‰¾å¯¹åº”ç« èŠ‚
    for section_type, question_templates in TEMPLATES.items():
        if section_type == "summary":
            continue  # å·²ç»å¤„ç†è¿‡

        # æ¨¡ç³ŠåŒ¹é…æ‰¾åˆ°ç« èŠ‚ï¼ˆæ”¯æŒå­ç« èŠ‚ï¼Œå¦‚ "Description > Appearance"ï¼‰
        matching_keys = [k for k in sections.keys() if section_type in k]

        for key in matching_keys:
            question = random.choice(question_templates).format(topic=topic)

            raw_answer = clean_text(sections[key])

            # æ ¹æ®ç±»å‹è°ƒæ•´å¥å­æ•°é‡
            if section_type == "Toxicity":
                short_answer = smart_shorten(raw_answer, max_sentences=2)  # æ¯’æ€§è¦ç®€çŸ­æœ‰åŠ›
            elif section_type == "Description":
                short_answer = smart_shorten(raw_answer, max_sentences=3)  # å¤–è§‚å¤šä¸€å¥
            else:
                short_answer = smart_shorten(raw_answer, max_sentences=2)

            if short_answer:
                formatted_data.append({
                    "text": f"User: {question}\nAssistant: {short_answer}<|im_end|>"
                })

            # æ¯ä¸ªç« èŠ‚ç±»å‹åªå–ä¸€ä¸ªåŒ¹é…ï¼ˆé¿å…é‡å¤ï¼‰
            break

# ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
import os
os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)

# ä¿å­˜
with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
    for entry in formatted_data:
        json.dump(entry, f, ensure_ascii=False)
        f.write('\n')

print("=" * 60)
print(f"ğŸ‰ å¤„ç†å®Œæˆï¼ç”Ÿæˆäº† {len(formatted_data)} æ¡ã€ç²¾ç®€ç‰ˆã€‘å¯¹è¯æ•°æ®ã€‚")
print(f"ğŸ“ æ•°æ®å·²ä¿å­˜åˆ°: {OUTPUT_FILE}")
print("=" * 60)
print(f"\nç¤ºä¾‹é¢„è§ˆ (å‰3æ¡):")
for i, example in enumerate(formatted_data[:3], 1):
    print(f"\n--- ç¤ºä¾‹ {i} ---")
    print(json.dumps(example, indent=2, ensure_ascii=False))
print("=" * 60)
