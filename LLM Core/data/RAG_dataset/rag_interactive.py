#!/usr/bin/env python3
"""
ğŸ’¬ RAG äº¤äº’å¼æŸ¥è¯¢ç³»ç»Ÿ
å®æ—¶å¯¹è¯å¼æŸ¥è¯¢è˜‘è‡çŸ¥è¯†åº“
"""

import chromadb
from chromadb.utils import embedding_functions
import subprocess

# ================= é…ç½® =================
CHROMA_DB_PATH = "data/RAG_dataset/chroma_db"
EMBEDDING_MODEL = "all-MiniLM-L6-v2"
OLLAMA_MODEL = "qwen2.5vl:32b"
TOP_K = 3  # æ£€ç´¢å‰3ä¸ªæ–‡æ¡£
# ========================================

def retrieve_docs(query: str, collection, top_k: int = TOP_K):
    """æ£€ç´¢ç›¸å…³æ–‡æ¡£"""
    results = collection.query(
        query_texts=[query],
        n_results=top_k
    )

    docs = []
    for doc, metadata, distance in zip(
        results['documents'][0],
        results['metadatas'][0],
        results['distances'][0]
    ):
        docs.append({
            "text": doc,
            "metadata": metadata,
            "similarity": 1 - distance
        })

    return docs

def generate_answer(query: str, context_docs: list):
    """ç”Ÿæˆç­”æ¡ˆ"""
    context = "\n\n".join([doc['text'] for doc in context_docs])

    prompt = f"""You are a mushroom expert. Answer based on the context provided.

Context:
{context}

Question: {query}

Answer (be concise and friendly):"""

    try:
        result = subprocess.run(
            ["ollama", "run", OLLAMA_MODEL, prompt],
            capture_output=True,
            text=True,
            timeout=45
        )
        return result.stdout.strip()
    except Exception as e:
        return f"Error: {e}"

def main():
    print("=" * 80)
    print("ğŸ’¬ è˜‘è‡çŸ¥è¯† RAG äº¤äº’å¼æŸ¥è¯¢")
    print("=" * 80)
    print("\nğŸ’¡ è¾“å…¥é—®é¢˜è¿›è¡ŒæŸ¥è¯¢ï¼Œè¾“å…¥ 'quit' æˆ– 'exit' é€€å‡º\n")

    # åˆå§‹åŒ–æ•°æ®åº“
    try:
        client = chromadb.PersistentClient(path=CHROMA_DB_PATH)
        embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(
            model_name=EMBEDDING_MODEL
        )
        collection = client.get_collection(
            name="mushroom_knowledge",
            embedding_function=embedding_function
        )
        print(f"âœ… å·²åŠ è½½çŸ¥è¯†åº“ ({collection.count()} ä¸ªæ–‡æ¡£)\n")
    except Exception as e:
        print(f"âŒ æ— æ³•åŠ è½½çŸ¥è¯†åº“: {e}")
        print("ğŸ’¡ è¯·å…ˆè¿è¡Œ: python data/RAG_dataset/build_rag_database.py")
        return

    # äº¤äº’å¾ªç¯
    while True:
        try:
            query = input("ğŸ„ ä½ çš„é—®é¢˜ > ").strip()

            if not query:
                continue

            if query.lower() in ['quit', 'exit', 'q']:
                print("\nğŸ‘‹ å†è§ï¼")
                break

            # æ£€ç´¢
            print(f"\nğŸ” æ£€ç´¢ä¸­...")
            docs = retrieve_docs(query, collection)

            # æ˜¾ç¤ºæ£€ç´¢ç»“æœ
            print(f"ğŸ“„ æ‰¾åˆ° {len(docs)} ä¸ªç›¸å…³æ–‡æ¡£:")
            for i, doc in enumerate(docs, 1):
                topic = doc['metadata'].get('topic', 'Unknown')
                section = doc['metadata'].get('section', '')
                similarity = doc['similarity']
                print(f"  [{i}] {topic} - {section} ({similarity:.0%})")

            # ç”Ÿæˆç­”æ¡ˆ
            print(f"\nğŸ¤– ç”Ÿæˆç­”æ¡ˆä¸­...")
            answer = generate_answer(query, docs)

            print(f"\nğŸ’¬ {answer}\n")
            print("-" * 80 + "\n")

        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ å†è§ï¼")
            break
        except Exception as e:
            print(f"\nâŒ é”™è¯¯: {e}\n")

if __name__ == "__main__":
    main()
